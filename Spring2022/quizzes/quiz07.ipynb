{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 7\n",
    "\n",
    "BEFORE YOU START THIS QUIZ:\n",
    "\n",
    "1. Click on \"Copy to Drive\" to make a copy of the quiz,\n",
    "\n",
    "2. Click on \"Share\",\n",
    "    \n",
    "3. Click on \"Change\" and select \"Anyone with this link can edit\"\n",
    "    \n",
    "4. Click \"Copy link\" and\n",
    "\n",
    "5. Paste the link into [this Canvas assignment](https://canvas.olin.edu/courses/390/assignments/6389).\n",
    "\n",
    "DO THIS BEFORE YOU START THE QUIZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function that just might come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "def make_lowess(series):\n",
    "    \"\"\"Use LOWESS to compute a smooth line.\n",
    "\n",
    "    series: pd.Series\n",
    "\n",
    "    returns: pd.Series\n",
    "    \"\"\"\n",
    "    endog = series.values\n",
    "    exog = series.index.values\n",
    "\n",
    "    smooth = lowess(endog, exog)\n",
    "    index, data = np.transpose(smooth)\n",
    "\n",
    "    return pd.Series(data, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating a Proportion\n",
    "\n",
    "Let's get some GSS data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "    \n",
    "download('https://github.com/AllenDowney/' +\n",
    "         'ElementsOfDataScience/raw/master/data/gss_eda.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gss = pd.read_hdf('gss_eda.hdf', 'gss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to recode `GRASS` so 1 means yes (supporting legalization of cannabis) and 0 means no (opposed to legalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss['grass'] = gss['GRASS'].replace(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I'll define `last` to be a Boolean Series that is `True` for the 2018 data, which is the last year in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = (gss['YEAR'] == 2018)\n",
    "last.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `count` to see how many valid (non-NaN) responses we have from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = gss[last]['grass'].count()\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Compute the fraction of valid responses that are `1` and assign that proportion to `p`. This is our estimate for the fraction of the population that supported legalization in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function from Notebook 13 simulates `n` coin tosses with probability `p`, and returns the number of heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_group_percent(n, p):\n",
    "    xs = np.random.random(size=n)\n",
    "    k = np.sum(xs < p)\n",
    "    return k / n * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Call `simulate_group_percent` 1000 times with the values of `n` and `p` we computed and save the results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following function to plot the sampling distribution of the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(t)\n",
    "\n",
    "plt.xlabel('Percent supporting legalization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Compute the standard error and 80% confidence interval for the estimated percentage.\n",
    "\n",
    "Note that I asked for an 80% interval, so that's different from what we've done previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating a Date\n",
    "\n",
    "Continuing the previous example, let's see how support for legalization has changed since 2000.\n",
    "Here's a Boolean Series that's true for data from 2000 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent = gss['YEAR'] >= 2000\n",
    "recent.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a Series that contains the fraction of people who said yes during each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = gss[recent].groupby('YEAR')['grass'].mean()\n",
    "smooth = make_lowess(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot(style='o', color='C2', alpha=0.5)\n",
    "smooth.plot(color='C2', alpha=0.5)\n",
    "\n",
    "plt.ylabel('Fraction supporting legalization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that support for legalization was less than 50% in 2000 and more than 50% in 2018, so we might wonder when it crossed the line.\n",
    "\n",
    "We can use interpolation of the smoothed line to estimate when it happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "func = interp1d(smooth.values, smooth.index)\n",
    "func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from `interp1d` is a function, which we can call like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the interpolation, support for legalization reached 50% in late 2011.\n",
    "The result is a NumPy array with a single value, but we can convert it to a float like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(func(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a single estimate; now suppose we would also like a confidence interval to quantify the precision of that estimate.\n",
    "We can do it by bootstrap resampling.\n",
    "For example, here's a version of the function from Notebook 12 we can use to bootstrap the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_mean(df):\n",
    "    bootstrapped = df.sample(n=len(df), replace=True)\n",
    "    return bootstrapped['grass'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_mean(gss[recent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Write a function called `bootstrap_year` that takes a DataFrame and runs the following steps:\n",
    "\n",
    "1. Use `sample` to generate a bootstrap sample of the rows.\n",
    "\n",
    "2. Use `groupby` and `mean` to compute the fraction of support for legalization during each year.\n",
    "\n",
    "3. Use `make_lowess` to fit a smooth curve to the data.\n",
    "\n",
    "4. Use `interp1d` to interpolate the year support was 50%.\n",
    "\n",
    "5. Return the result as a float (not an array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call your function like this to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_year(gss[recent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Call `bootstrap_year` 1000 times, save the results, and use them to compute a 90% CI for the estimated year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that we can use bootstrap resampling to compute confidence intervals for pretty much any estimation process, even one like this that involves computations like local regression and interpolation.\n",
    "This example would be all but impossible to do mathematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help a Redditor Out\n",
    "\n",
    "A recent question on [r/stats](https://www.reddit.com/r/statistics/comments/tyi36l/q_what_is_the_correct_way_to_compare_these_two/) asks:\n",
    "\n",
    "> [Q] What is the correct way to compare these two means?\n",
    "> \n",
    "> Simple question but my statistics knowledge is rusty so I’m hoping to get some help. I am preparing a report and have water concentration data for two locations.\n",
    "> \n",
    "> Location A: 214, 256, 218, 268. Mean 239.\n",
    "> \n",
    "> Location B: 180, 181, 161. Mean 174.\n",
    "> \n",
    "> I want to state “average concentration at location B is X% lower than at location A”. What is the correct formula to use to determine the percentage?\n",
    "> \n",
    "> I do not need to speak to the statistical significance of the difference, but if I did, would I use a t-test?\n",
    "> \n",
    "> Thanks!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the data in two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_a = np.array([214, 256, 218, 268])\n",
    "loc_b = np.array([180, 181, 161])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** The question implies that the appropriate test statistic in this case is the *decrease* in the average at B expressed as a percentage of the average at A. Write a line of code to compute this test statistic for the given data.\n",
    "\n",
    "Hint: Since the question is specifically about a decrease, you should not compute the absolute value of the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** To see whether this apparent effect could be due to chance, let's use permutation. Write a function called `simulate_two_groups` that takes the two data arrays as parameters, combines the two groups, shuffles them, divides the shuffled values into two groups with the same sizes are the originals, then computes and returns the test statistic of the shuffled data.\n",
    "\n",
    "Hint: Start with a similar function from Notebook 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call your function like this to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_two_groups(loc_a, loc_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:** Call your function 1000 times and save the results as a list. Use this list to estimate the p-value of the observed effect. Write a sentence to interpret the results; is it plausible that the observed effect it due to chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional just for fun extra question:** If the original question asked about the *difference* between A and B, rather than the decrease at B relative to A, it would be more appropriate to use the absolute value of the difference as a test statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Elements of Data Science*\n",
    "\n",
    "Copyright 2022 Allen Downey\n",
    "\n",
    "License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
